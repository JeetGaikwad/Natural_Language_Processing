{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPUoYf7SpPHH"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOL0FIv-t80L"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyUGmxUEyGzX"
   },
   "outputs": [],
   "source": [
    "text = list(df.text.values)\n",
    "joined_text = \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mocx68q1yPIh",
    "outputId": "6002e03d-e60a-45fd-db17-9ece5cb5e2ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29826765"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtnHhcS1yQRl"
   },
   "outputs": [],
   "source": [
    "partial_text = joined_text[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FbjOhGAEygY-"
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5EsMREusy7zJ"
   },
   "outputs": [],
   "source": [
    "unique_tokens = np.unique(tokens)\n",
    "unique_token_index = {token: idx for idx, token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5qB04HRzEJk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOH7LddIzrGx"
   },
   "outputs": [],
   "source": [
    "n_words = 10\n",
    "inp_words = []\n",
    "next_words = []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "  inp_words.append(tokens[i:i + n_words])\n",
    "  next_words.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RaYtNqm0t_L"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(inp_words), n_words, len(unique_tokens)), dtype=bool)\n",
    "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBgFmbD82KoL"
   },
   "outputs": [],
   "source": [
    "for i,words in enumerate(inp_words):\n",
    "  for j,word in enumerate(words):\n",
    "    X[i,j, unique_token_index[word]] = 1\n",
    "  y[i, unique_token_index[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qB9GJJm63BHR"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6KWO7kY-XYI",
    "outputId": "59157fd1-cec2-4aea-f7d0-2182626c8e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "135/135 [==============================] - 53s 346ms/step - loss: 0.2324 - accuracy: 0.9731\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 45s 333ms/step - loss: 0.1803 - accuracy: 0.9803\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 47s 349ms/step - loss: 0.1471 - accuracy: 0.9833\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 44s 329ms/step - loss: 0.1386 - accuracy: 0.9825\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 46s 345ms/step - loss: 0.1351 - accuracy: 0.9825\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 42s 308ms/step - loss: 0.1139 - accuracy: 0.9859\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 44s 326ms/step - loss: 0.1168 - accuracy: 0.9825\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 44s 323ms/step - loss: 0.1074 - accuracy: 0.9851\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 44s 328ms/step - loss: 0.0991 - accuracy: 0.9864\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 44s 327ms/step - loss: 0.0978 - accuracy: 0.9841\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 42s 312ms/step - loss: 0.0916 - accuracy: 0.9869\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 44s 325ms/step - loss: 0.0862 - accuracy: 0.9867\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 41s 304ms/step - loss: 0.0856 - accuracy: 0.9860\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 44s 324ms/step - loss: 0.0931 - accuracy: 0.9840\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 42s 310ms/step - loss: 0.0885 - accuracy: 0.9861\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 41s 304ms/step - loss: 0.0808 - accuracy: 0.9878\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 41s 304ms/step - loss: 0.0838 - accuracy: 0.9859\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 41s 307ms/step - loss: 0.0919 - accuracy: 0.9825\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 42s 312ms/step - loss: 0.0849 - accuracy: 0.9843\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 41s 303ms/step - loss: 0.0726 - accuracy: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a3b78e44910>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01), metrics=['accuracy'])\n",
    "model.fit(X,y, batch_size=128, epochs=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Dd1Nr6H2AB_F"
   },
   "outputs": [],
   "source": [
    "model.save(\"Mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "zG7JGSN-Azm5"
   },
   "outputs": [],
   "source": [
    "model = load_model(\"Mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "GJGVIdmAA5BO"
   },
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, n_best):\n",
    "  input_text = input_text.lower()\n",
    "  X = np.zeros((1, n_words, len(unique_tokens)))\n",
    "  for i, word in enumerate(input_text.split()):\n",
    "    X[0, i, unique_token_index[word]] = 1\n",
    "\n",
    "  predictions = model.predict(X)[0]\n",
    "  return np.argpartition(predictions, -n_best)[-n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6rNCkUCsA6YJ",
    "outputId": "c69b626b-28ac-42f2-c4b7-ea028322f56e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "possible = predict_next_word(\"see this\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSoLzNSoEAZi",
    "outputId": "f4b2aaf8-329c-4ca3-c0e1-eeca65f09069"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 322,   98, 3217, 3616, 3601, 1649, 1741,  528, 1192, 2237])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9r0kQ6uzEO1r",
    "outputId": "d3ea6b71-df43-49af-8cc7-044bedb2ff99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'a', 'supports', 'who', 'well', 'in', 'is', 'but', 'even', 'now']\n"
     ]
    }
   ],
   "source": [
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "gQ_u-wgaEt-u"
   },
   "outputs": [],
   "source": [
    "def generate_text(input_text, text_length, creativity=3):\n",
    "  word_sequence = input_text.split()\n",
    "  current = 0\n",
    "  for _ in range(text_length):\n",
    "    sub_seq = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current:current+ n_words])\n",
    "    try:\n",
    "      choice = unique_tokens[random.choice(predict_next_word(sub_seq, creativity))]\n",
    "    except:\n",
    "      choice = random.choice(unique_tokens)\n",
    "    word_sequence.append(choice)\n",
    "    current += 1\n",
    "  return \" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nF6MnDbAGOzC",
    "outputId": "1acfa1b8-8bc1-4408-8f61-f41b35b71857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'He is trying to understand that kgb action door sanctions how we we years such problems trump it trump men long both leaders a a a a all little it we we many we we with it we we we we we for we we details ayotte this in trump her and because we we we we we we home it it we we we we supporting we we we with and we we we we we with it it we we we we supporting we we we with and we we we we we with it it we we we we supporting we we we'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"He is trying to understand that\",100, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSJs-Vl1GRpl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
